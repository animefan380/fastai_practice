{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Copy of 04_mnist_basics.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/animefan380/fastai_practice/blob/main/Copy_of_04_mnist_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJcj3sCbUTUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d830cfea-78fe-4949-855f-bb381468c46a"
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 727kB 5.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 10.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 13.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DGEUyKRUTU-"
      },
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zauy1PPCUTU_"
      },
      "source": [
        "[[chapter_mnist_basics]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY9Cxp1iUTVA"
      },
      "source": [
        "# Under the Hood: Training a Digit Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUgIy7pKUTVE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f2fd5f97-c07f-479b-a39d-833623e19fd1"
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIjurO69UTVE"
      },
      "source": [
        "#hide\n",
        "Path.BASE_PATH = path"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlN1DciKUTVH"
      },
      "source": [
        "zeroes = (path/'training'/'0').ls().sorted()\n",
        "ones = (path/'training'/'1').ls().sorted()\n",
        "twos = (path/'training'/'2').ls().sorted()\n",
        "threes = (path/'training'/'3').ls().sorted()\n",
        "fours = (path/'training'/'4').ls().sorted()\n",
        "fives = (path/'training'/'5').ls().sorted()\n",
        "sixes = (path/'training'/'6').ls().sorted()\n",
        "sevens = (path/'training'/'7').ls().sorted()\n",
        "eights = (path/'training'/'8').ls().sorted()\n",
        "nines = (path/'training'/'9').ls().sorted()\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytH1kH3QUTVL"
      },
      "source": [
        "## First Try: Pixel Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Ro7MCfUTVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1678168b-5426-4502-8d73-d9b6b1323fce"
      },
      "source": [
        "zero_tensors = [tensor(Image.open(o)) for o in zeroes]\n",
        "one_tensors = [tensor(Image.open(o)) for o in ones]\n",
        "two_tensors = [tensor(Image.open(o)) for o in twos]\n",
        "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
        "four_tensors = [tensor(Image.open(o)) for o in fours]\n",
        "five_tensors = [tensor(Image.open(o)) for o in fives]\n",
        "six_tensors = [tensor(Image.open(o)) for o in sixes]\n",
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
        "eight_tensors = [tensor(Image.open(o)) for o in sevens]\n",
        "nine_tensors = [tensor(Image.open(o)) for o in nines]\n",
        "\n",
        "\n",
        "len(three_tensors),len(seven_tensors)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6131, 6265)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTwuF8_fUTVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e499ada0-6455-4cde-f32f-5e08ac1cf519"
      },
      "source": [
        "stacked_zeroes = torch.stack(zero_tensors).float()/255\n",
        "stacked_ones = torch.stack(one_tensors).float()/255\n",
        "stacked_twos= torch.stack(two_tensors).float()/255\n",
        "stacked_threes = torch.stack(three_tensors).float()/255\n",
        "stacked_fours = torch.stack(four_tensors).float()/255\n",
        "stacked_fives = torch.stack(five_tensors).float()/255\n",
        "stacked_sixes = torch.stack(six_tensors).float()/255\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
        "stacked_eights = torch.stack(eight_tensors).float()/255\n",
        "stacked_nines = torch.stack(nine_tensors).float()/255\n",
        "\n",
        "\n",
        "stacked_nines.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5949, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voJhJrYhUTVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6efae862-e3bf-4160-d75d-2b842ba0bc68"
      },
      "source": [
        "valid_0_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'0').ls()]).float()/255\n",
        "valid_1_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'1').ls()]).float()/255\n",
        "valid_2_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'2').ls()]).float()/255\n",
        "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'3').ls()]).float()/255\n",
        "valid_4_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'4').ls()]).float()/255\n",
        "valid_5_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'5').ls()]).float()/255\n",
        "valid_6_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'6').ls()]).float()/255\n",
        "valid_6_tens = valid_6_tens.float()/255\n",
        "\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'7').ls()]).float()/255\n",
        "\n",
        "valid_8_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'8').ls()]).float()/255\n",
        "\n",
        "valid_9_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'testing'/'9').ls()]).float()/255\n",
        "valid_9_tens = valid_9_tens.float()/255\n",
        "\n",
        "valid_6_tens.shape,valid_9_tens.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([958, 28, 28]), torch.Size([1009, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuQpd0l9UTVh"
      },
      "source": [
        "def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOgQEjNeUTVj"
      },
      "source": [
        "def is_6(x): return mnist_distance(x,mean6) < mnist_distance(x,mean9)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhHPHXMuUTV2"
      },
      "source": [
        "## The MNIST Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTU6QeKyUTV3"
      },
      "source": [
        "train_x = torch.cat([stacked_zeroes,\r\n",
        "                     stacked_ones,\r\n",
        "                     stacked_twos,\r\n",
        "                     stacked_threes,\r\n",
        "                     stacked_fours,\r\n",
        "                     stacked_fives,\r\n",
        "                     stacked_sixes,\r\n",
        "                     stacked_sevens,\r\n",
        "                     stacked_eights,\r\n",
        "                     stacked_nines]).view(-1, 28*28)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJISuf5jUTV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fe01b3c-501a-4ffd-c060-29d40cd31dcc"
      },
      "source": [
        "train_y = tensor([0]*len(zeroes) +\n",
        "                [1]*len(ones) + \n",
        "                [2]*len(twos) + \n",
        "                [3]*len(threes) +\n",
        "                 [4]*len(fours) +\n",
        "                 [5]*len(fives) +\n",
        "                 [6]*len(sixes) +\n",
        "                 [7]*len(sevens) +\n",
        "                 [8]*len(eights) +\n",
        "                 [9]*len(nines)).unsqueeze(1)\n",
        "train_x.shape,train_y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60414, 784]), torch.Size([60000, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6vuVrt2UTV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffca8cd-8cf2-4f03-a575-23a9dfd8c499"
      },
      "source": [
        "dset = list(zip(train_x,train_y))\n",
        "x,y = dset[0]\n",
        "x.shape,y"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), tensor([0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3Gt8TKJUTV4"
      },
      "source": [
        "valid_x = torch.cat([valid_0_tens,\n",
        "                     valid_1_tens,\n",
        "                     valid_2_tens,\n",
        "                     valid_4_tens,\n",
        "                     valid_5_tens,\n",
        "                     valid_6_tens,\n",
        "                     valid_7_tens,\n",
        "                     valid_8_tens,\n",
        "                     valid_9_tens,\n",
        "                     ]).view(-1, 28*28)\n",
        "valid_y = tensor([0]*len(valid_0_tens) + \n",
        "                 [1]*len(valid_1_tens) +\n",
        "                 [2]*len(valid_2_tens) + \n",
        "                 [3]*len(valid_3_tens) + \n",
        "                 [4]*len(valid_4_tens) + \n",
        "                 [5]*len(valid_5_tens) + \n",
        "                 [6]*len(valid_6_tens) + \n",
        "                 [7]*len(valid_7_tens) + \n",
        "                 [8]*len(valid_8_tens) + \n",
        "                 [9]*len(valid_9_tens)).unsqueeze(1)\n",
        "valid_dset = list(zip(valid_x,valid_y))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2qeV76NR5te",
        "outputId": "55cfd817-3227-49a1-b981-834a51a77dd3"
      },
      "source": [
        "valid_x.shape,valid_y.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8990, 784]), torch.Size([10000, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG6f7rmtUTV4"
      },
      "source": [
        "Now we need an (initially random) weight for every pixel (this is the *initialize* step in our seven-step process):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyi77l10UTV4"
      },
      "source": [
        "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95AHjTf3UTV4"
      },
      "source": [
        "weights = init_params((28*28,1))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PiSZBbWUTV4"
      },
      "source": [
        "bias = init_params(1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYHz02pQUTV5"
      },
      "source": [
        "We can now calculate a prediction for one image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6NQECUzUTV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5c9e64-9341-48ef-e5b7-00618e49bee3"
      },
      "source": [
        "(train_x[0]*weights.T).sum() + bias"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9.2751], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCGqIDnzUTV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7cf3ee-9477-405f-e994-53716ad07b85"
      },
      "source": [
        "def linear1(xb): return xb@weights + bias\n",
        "preds = linear1(train_x)\n",
        "preds"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -9.2751],\n",
              "        [-23.0076],\n",
              "        [-15.8010],\n",
              "        ...,\n",
              "        [ -8.8975],\n",
              "        [-10.6736],\n",
              "        [ -6.4075]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2tidhVGUTV7"
      },
      "source": [
        "Let's check our accuracy. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0, so our accuracy for each item can be calculated (using broadcasting, so no loops!) with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M66vwOTHUTV7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "b6dfd34a-bc75-4ec3-9c74-ba66392750f9"
      },
      "source": [
        "corrects = (preds).float() == train_y\n",
        "corrects"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-6ea78f43a091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorrects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (60414) must match the size of tensor b (60000) at non-singleton dimension 0"
          ]
        }
      ]
    }
  ]
}